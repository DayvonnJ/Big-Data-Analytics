{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19c90514",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c1475",
   "metadata": {},
   "source": [
    "### [Note] you need customize the code template to replace \"?\" with your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "082f5142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# packages for preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# packages for model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# packages for model evaluation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.inspection import PartialDependenceDisplay, plot_partial_dependence\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853405a0",
   "metadata": {},
   "source": [
    "# 1. Read in data [5pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af25638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize the following code to read in the final.csv that is saved under the final folder\n",
    "df = pd.read_csv(?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6434899",
   "metadata": {},
   "source": [
    "## Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5e647c",
   "metadata": {},
   "source": [
    "1. ['FC ', 'OT ', 'JC ', 'E  ', 'A  ', 'D  ', 'I  ', 'FJ ', 'IE ', 'F  ','FA ', 'B  ', 'AC ', ' C ', 'IC ', 'AH ', ' E ', 'JF ', 'EF '] \n",
    "these columns are binary indicators, suggesting what the type of medcaid program the participant is in. Specifically,\n",
    "\n",
    "           A  Aged\n",
    "           B  Blind\n",
    "           D  Disabled\n",
    "           E  Medically Needy\n",
    "           I  Institutional Medicaid\n",
    "           FC (ACA) Family Care (Only)\n",
    "           JC Jersey Care (Only)\n",
    "           IE Institutional (Medically Needy)\n",
    "           IH Institutional (Assisted Living)\n",
    "           OT Other\n",
    "\n",
    "Some cases have combined programs, Combine The Case Types, e.g., FA - Family Care & Aged\n",
    "   \n",
    "2. 'duration', number of years the participant is in the program (from the starting date to the last applciation date)\n",
    "3. 'age_lastyear', the age of applicant (in the last application year)\n",
    "4. 'GENDER', applicant gender as recorded in the system. F indicates female, M indicates male, there are also empty values, which may indicates other or simply missing.\n",
    "5. 'HHSIZE', household size\n",
    "6. 'num_kids_lastyear', number of kids in the household by the time of the last application\n",
    "7. 'novehicle', a binary indicator suggesting whether the household has no vehicle. The value will be 1 if the household does not have access to a vehicle\n",
    "8. 'work_income', annual income from work (estimated by multiplying each pay check with frequency, the data were messy so some numbers are very large, you may need to decide wether you want to remove outliers)\n",
    "9. 'nonwork_income', annual income from non-work sources, e.g., pension. \n",
    "10. 'total_income', the summation of the work and non-work related income\n",
    "\n",
    "\n",
    "Target variable is the 'target'. It's a binary variable indicating whether the applicant successfully left the program or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90edbb32",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing [10pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446bfb77",
   "metadata": {},
   "source": [
    "## 2.1 Split data into training (80%) and testing (20%) data [5pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54885e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(?)\n",
    "y = df[?]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=?\n",
    "                                                    , random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9995c976",
   "metadata": {},
   "source": [
    "## 2.2 What column in X_train has missing values and what percent have missing values? Please pick a method you have learned to pre-process the missing values. [5pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35197661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show columns with % of missing values\n",
    "?.isnull().sum()/len(?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163e057",
   "metadata": {},
   "source": [
    "Let's drop records with missing values before we develop machine learning models, hint please use the dropna function that comes with pandas dataframe to drop records with missing values (e.g., if you want to drop all records with na values in df dataframe, then the code is df = df.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3348630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to drop na\n",
    "X_train = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ca1b04",
   "metadata": {},
   "source": [
    "# 3. Data Balancing [10pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7102a754",
   "metadata": {},
   "source": [
    "## 3.1 How many ones (i.e., people who successfulll leave the program) and zeros (i.e., people who are still in the program) are there in your training target? [2pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83760369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (hint the value_counts() function can be handy here)\n",
    "y.?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94abb98",
   "metadata": {},
   "source": [
    "## 3.2 The data is unbalanced as there are more zeros than ones. Please customize the following code to balance the training data using the upsampling method [8pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2391e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = X_train.copy()\n",
    "df_train[\"target\"] = y_train\n",
    "\n",
    "df_minority = df_train[df_train[\"target\"] == ?]\n",
    "df_majority = df_train[df_train[\"target\"] == ?]\n",
    "df_upsampled = resample(df_?, n_samples = len(df_?), replace=?)\n",
    "df_upsampled = pd.concat([df_upsampled, df_majority])\n",
    "X_train_upsampled = df_upsampled.drop(\"target\", axis = 1)\n",
    "y_train_upsampled = df_upsampled[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babf5d71",
   "metadata": {},
   "source": [
    "# 4. Gradient Boosting Classifier Tuning [15pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebd3592",
   "metadata": {},
   "source": [
    "## 4.1 Evaluation metrics selection. If Union County director is concerned about both the recall and precision of the model, what metrics do you suggest to use to evaluate model performance? [5pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2e580c",
   "metadata": {},
   "source": [
    "your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24362a44",
   "metadata": {},
   "source": [
    "## 4.2 Customize the following code to fine tune a gradient boosting classifier given your selected metrics. [5pts]\n",
    "\n",
    "Please ensure the following hyperparameters are finetuned:\n",
    "1. n_estimators\n",
    "2. max_depth\n",
    "3. learning_rate\n",
    "4. max_features\n",
    "5. min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below are old codes from class, you need to customize the code.\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score # load gridserach cross validation package\n",
    "\n",
    "space  = [Integer(60,100, name=\"n_estimators\"),\n",
    "            Integer(5, 8, name='max_depth'), #integers\n",
    "          Integer(2, 9, name='max_features'),\n",
    "          Integer(100, 150, name='min_samples_split')] \n",
    "\n",
    "rf  =  RandomForestRegressor(random_state=0)\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    rf.set_params(**params)\n",
    "\n",
    "    return np.mean(cross_val_score(rf, X, y, cv=5, n_jobs=-1,scoring=\"neg_mean_absolute_error\"))\n",
    "\n",
    "rf_gp = gp_minimize(objective, space, n_calls=50, random_state=0)\n",
    "\n",
    "\"Best score=%.4f\" % rf_gp.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd8850a",
   "metadata": {},
   "source": [
    "## 4.3 What are the best combination of the hyperparameter? [5pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2544b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below are old codes from class, you need to customize the code.\n",
    "print(\"\"\"Best parameters:\n",
    "- n_estimators = %d\n",
    "- max_depth=%d\n",
    "- max_features=%d\n",
    "- min_samples_split=%d\"\"\" % (rf_gp.x[0], rf_gp.x[1],\n",
    "                            rf_gp.x[2], rf_gp.x[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7497dc",
   "metadata": {},
   "source": [
    "# 5. Testing Model Peformance on the Test Dataset [15pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69719bb6",
   "metadata": {},
   "source": [
    "## 5.1 drop records with na values in X_test [1pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d61e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test =? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aea56bd",
   "metadata": {},
   "source": [
    "## 5.2 Develop Gradient Boosting Model with the best hyperparameters using the training set [4pts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59589618",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gb = ?# initialize your gradient boosting model wit hteh hyperparameters you get from 4.3\n",
    "best_gb.fit(?, ?) # customize inputs so that the model is fitted to your training datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e507a3",
   "metadata": {},
   "source": [
    "## 5.3 Apply the trained GBM to test dataset [1pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013d0e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize predict function inputs so the model predict outcomes for your testing datasets\n",
    "y_predict = best_gb.predict(?, ? )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cbfebb",
   "metadata": {},
   "source": [
    "## 5.4 Calculate the following evaluation metrics for the mdoel output [9pts]\n",
    "\n",
    "1. Precision\n",
    "2. Recall\n",
    "3. f1 score\n",
    "4. Confusion matrix\n",
    "4. ROC\n",
    "\n",
    "Do you think the model outfit the training data set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8af1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize the code here to get Precsion, Recall, and F1 score\n",
    "y_predict_rf = best_rfc.predict(X_test)\n",
    "\n",
    "precision, recall, fscore, support = score(y_test, y_predict_rf) #support = no. of observations in each category\n",
    "df_rf = pd.DataFrame({\n",
    "    \"labels\":list(range(len(y_test.value_counts().index))),\n",
    "    'precision':precision,\n",
    "    \"recall\": recall,\n",
    "    \"fscore\": fscore,\n",
    "    \"support\": support # number of cases in the category in the observed dataset\n",
    "    \n",
    "})\n",
    "\n",
    "df_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661eac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize teh code here to get confusion matrix\n",
    "plot_confusion_matrix(best_rfc , X_test, y_test)\n",
    "plt.savefig(\"figures/confusion_matrix.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb8e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize teh code here to get confusion matrix\n",
    "y_repdict_proba = best_rfc.predict_proba(X_test)\n",
    "roc_auc_score (y_test, y_repdict_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f02c831",
   "metadata": {},
   "source": [
    "# 6 Interprete Model Results [15pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce83f97",
   "metadata": {},
   "source": [
    "# 6.1 What are the top 6 important features from the model? [5pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bcc4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# example code from Assignment 2, please customize\n",
    "rfr_imp_score = pd.DataFrame({\n",
    "    \"features\" : X.columns,\n",
    "    \"score\" : best_rfr.feature_importances_})\n",
    "rfr_imp_score.sort_values(\"score\", ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daf285e",
   "metadata": {},
   "source": [
    "## 6.2 PDP plots [5pts]\n",
    "\n",
    "Generate pdp plots to each of the top 6 important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6973e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customized the code below to show PDP plots\n",
    "PartialDependenceDisplay.from_estimator(best_rfr, X, \n",
    "                                        [\"RM\", \"LSTAT\", \"NOX\", \"PTRATIO\", \"INDUS\"])\n",
    "plt.savefig(\"figures/PDPs.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7949e2",
   "metadata": {},
   "source": [
    "## 6.3 Interactions [5pts]\n",
    "\n",
    "Please examine if there is any interations among the top 6 important features in the model using the contour PDP plots. You don't have to exhaust all combinations, but just a couple that you believe may have interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb22a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customized the code below to show interaction plots, you may add cells below to explore more combinations\n",
    "plot_partial_dependence (best_rfr, X, [(0,6)],\n",
    "                                  feature_names=X.columns)\n",
    "plt.savefig(\"figures/Interactions.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d01f70d",
   "metadata": {},
   "source": [
    "# 7. Finish the final project report [30pts]\n",
    "\n",
    "Requirements are as follow (please also refer to the example final project as reference)\n",
    "\n",
    "**Report Structure**\n",
    "1.\tIntroduction/Background (I have included a map of people who are current in the medcaird program in the figures subfolder, you may want to reference it if you want to)\n",
    "3.\tData Preprocessing, such as data imputation, transformation, etc.\n",
    "4.\tMachine learning model pipeline design, such as justifying what model has been used, how you finetune the model, how do you evaluate the model, etc.\n",
    "5.\tMachine learning results (e.g., f1, recall, fusion matrix, etc.)\n",
    "6.\tInterpretable machine learning, i.e., what variables are important in prediction, what are the possible non-linear and threshold effects of the selected important variables that may have policy implications. \n",
    "7.\tConclusion\n",
    "\n",
    "**Reprot Format**\n",
    "1. Double spaced\n",
    "2. Times New Roman font 12\n",
    "3. Margins 1 inch each side\n",
    "4. Maximum 10 pages of text plus appendix, references etc.\n",
    "5. Minimum 8 pages of text plus appendix, references etc.\n",
    "6. Proofread your paper before handing it in\n",
    "7. Use proper and consistent citations (choose one style and stick with it)\n",
    "8. Use clear and precise language, explain your thoughts\n",
    "9. Use high quality images for references in the report (**Hint, the images produced by this jupyter notebook will be saved under the figures subfolder**)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
